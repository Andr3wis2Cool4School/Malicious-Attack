{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ea73d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3d659b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    #BREAKING: A Germanwings Airbus A320 has crash...\n",
       " 1    Updated numbers @AP: BREAKING: #Germanwings CE...\n",
       " 2    @YanniKouts @germanwings @flightradar24 A bit ...\n",
       " 3    #Germanwings co-pilot suffered serious depress...\n",
       " 4    @ThisIsGaZa إِنَّا لِلّهِ وَإِنَّـا إِلَيْهِ ر...\n",
       " Name: Text, dtype: object,\n",
       " 0    rumours\n",
       " 1    rumours\n",
       " 2    rumours\n",
       " 3    rumours\n",
       " 4    rumours\n",
       " Name: Label, dtype: object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Pheme.csv')\n",
    "X = df['Text']\n",
    "y = df['Label']\n",
    "\n",
    "X.head(), y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e5f7070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7bf8f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dd0bda31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5140, 5140)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c9eb3b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1286, 1286)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "653627b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a1a34614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3408    0\n",
       "577     1\n",
       "3077    0\n",
       "6308    1\n",
       "2558    0\n",
       "       ..\n",
       "179     1\n",
       "3291    0\n",
       "2435    0\n",
       "5750    0\n",
       "6188    0\n",
       "Name: Label, Length: 1286, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def label(x):\n",
    "    if x == 'rumours':\n",
    "        x = 1\n",
    "    elif x == 'non-rumours':\n",
    "        x = 0\n",
    "    return x\n",
    "\n",
    "y_test = y_test.apply(lambda x: label(x))\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "689ba69b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 0,  ..., 0, 0, 0])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.tensor(y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "264576fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.,  ..., 0., 0., 0.], dtype=torch.float64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y.apply(lambda x: label(x))\n",
    "torch.tensor(y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93c963de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f357ca4d",
   "metadata": {},
   "source": [
    "`torch.nn.Embedding`:\n",
    "\n",
    "**torch.nn.Emebdding(num_embeddings, embedding_dim)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e7034ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-1.6270, -0.5891,  1.0201,  0.2022],\n",
       "          [-1.6835, -1.4850, -0.5055,  0.4733],\n",
       "          [ 1.8186,  0.6548, -0.1640,  0.4837]],\n",
       " \n",
       "         [[-1.6835, -1.4850, -0.5055,  0.4733],\n",
       "          [ 1.8186,  0.6548, -0.1640,  0.4837],\n",
       "          [-0.1582,  1.0103,  0.4638,  0.9874]]], grad_fn=<EmbeddingBackward0>),\n",
       " torch.Size([2, 3, 4]),\n",
       " torch.Size([2, 3, 4]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = nn.Embedding(5, 4) # total 5 words, each words have 4 dims\n",
    "'''\n",
    "the shape is (2, 3).\n",
    "        |||\n",
    "Word is like a batch, the batch size is 2, which means we have two data sample.\n",
    "Each data sample have 3 words, which equals to the padding length or num_steps.\n",
    "\n",
    "'''\n",
    "word = [[1, 2, 3], \n",
    "        [2, 3, 4]]\n",
    "\n",
    "embed = embedding(torch.LongTensor(word))\n",
    "embed, embed.size(), embed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fac3b52",
   "metadata": {},
   "source": [
    "The output is `(2, 3, 4)`.\n",
    "Which is **(batch_size, padding_length, word_dims)**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf38561a",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_embedding_path = '../../glove.6B.100d/vec.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ed3a78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the -0.038194 -0.24487 0.72812 -0.39961 0.083172 0.043953 -0.39141 0.3344 -0.57545 0.087459 0.28787 -0.06731 0.30906 -0.26384 -0.13231 -0.20757 0.33395 -0.33848 -0.31743 -0.48336 0.1464 -0.37304 0.34577 0.052041 0.44946 -0.46971 0.02628 -0.54155 -0.15518 -0.14107 -0.039722 0.28277 0.14393 0.23464 -0.31021 0.086173 0.20397 0.52624 0.17164 -0.082378 -0.71787 -0.41531 0.20335 -0.12763 0.41367 0.55187 0.57908 -0.33477 -0.36559 -0.54857 -0.062892 0.26584 0.30205 0.99775 -0.80481 -3.0243 0.01254 -0.36942 2.2167 0.72201 -0.24978 0.92136 0.034514 0.46745 1.1079 -0.19358 -0.074575 0.23353 -0.052062 -0.22044 0.057162 -0.15806 -0.30798 -0.41625 0.37972 0.15006 -0.53212 -0.2055 -1.2526 0.071624 0.70565 0.49744 -0.42063 0.26148 -1.538 -0.30223 -0.073438 -0.28312 0.37104 -0.25217 0.016215 -0.017099 -0.38984 0.87424 -0.72569 -0.51058 -0.52028 -0.1459 0.8278 0.27062\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(glove_embedding_path, 'r') as f:\n",
    "    for line in f:\n",
    "        a = line\n",
    "        print(a)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b321e783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e335b9f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', '-0.038194', '-0.24487']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elems = a.rstrip().split(' ')\n",
    "elems[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1794ce3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [2, 3, 4]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor can be slicing\n",
    "\n",
    "l = [[1, 2, 3], \n",
    "     [2, 3, 4],\n",
    "     [3, 3, 1]]\n",
    "l = torch.tensor(l)\n",
    "\n",
    "l[torch.tensor([0, 1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd4a1e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenEmbedding:\n",
    "    def __init__(self, embedding_path):\n",
    "        '''\n",
    "        We need to create three things:\n",
    "        1. idx_to_token\n",
    "        2. idx_to_vec\n",
    "        3. token_to_idx\n",
    "        '''\n",
    "        self.idx_to_token, self.idx_to_vec = self._load_embedding(embedding_path)\n",
    "        self.unknown_idx = 0\n",
    "        self.token_to_idx = {token: idx for idx, token in enumerate(self.idx_to_token)}\n",
    "    \n",
    "    def _load_embedding(self, embedding_path):\n",
    "        idx_to_token, idx_to_vec = ['<unk>'], []\n",
    "        with open(embedding_path, 'r') as f:\n",
    "            for line in f:\n",
    "                elems = line.rstrip().split(' ')\n",
    "                token, elems = elems[0], [float(elem) for elem in elems[1:]]\n",
    "                # of course it will always be greater than one!!!\n",
    "                if len(elems) > 1:\n",
    "                    idx_to_token.append(token)\n",
    "                    idx_to_vec.append(elems)\n",
    "        '''\n",
    "        After that we need to add ['<unk>'] using all 0 vectors.\n",
    "        '''\n",
    "        idx_to_vec = [[0] * len(idx_to_vec[0])] + idx_to_vec\n",
    "        return idx_to_token, torch.tensor(idx_to_vec)\n",
    "    \n",
    "    def __getitem__(self, tokens):\n",
    "        indices = [self.token_to_idx.get(token, self.unknown_idx)\n",
    "                   for token in tokens]\n",
    "        vecs = self.idx_to_vec[torch.tensor(indices)]\n",
    "        return vecs\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.idx_to_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ccd1f219",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_embedding = TokenEmbedding(glove_embedding_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebad4f0c",
   "metadata": {},
   "source": [
    "What the `TokenEmbedding` class does is that:\n",
    "\n",
    "It takes token's idx in the `Vocab` class, \n",
    "and use `__getitem__` in itself, mapping them to vecs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
