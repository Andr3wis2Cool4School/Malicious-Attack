{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ea73d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3d659b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    #BREAKING: A Germanwings Airbus A320 has crash...\n",
       " 1    Updated numbers @AP: BREAKING: #Germanwings CE...\n",
       " 2    @YanniKouts @germanwings @flightradar24 A bit ...\n",
       " 3    #Germanwings co-pilot suffered serious depress...\n",
       " 4    @ThisIsGaZa إِنَّا لِلّهِ وَإِنَّـا إِلَيْهِ ر...\n",
       " Name: Text, dtype: object,\n",
       " 0    rumours\n",
       " 1    rumours\n",
       " 2    rumours\n",
       " 3    rumours\n",
       " 4    rumours\n",
       " Name: Label, dtype: object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Pheme.csv')\n",
    "X = df['Text']\n",
    "y = df['Label']\n",
    "\n",
    "X.head(), y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e5f7070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7bf8f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dd0bda31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5140, 5140)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c9eb3b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1286, 1286)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "653627b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a1a34614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3408    0\n",
       "577     1\n",
       "3077    0\n",
       "6308    1\n",
       "2558    0\n",
       "       ..\n",
       "179     1\n",
       "3291    0\n",
       "2435    0\n",
       "5750    0\n",
       "6188    0\n",
       "Name: Label, Length: 1286, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def label(x):\n",
    "    if x == 'rumours':\n",
    "        x = 1\n",
    "    elif x == 'non-rumours':\n",
    "        x = 0\n",
    "    return x\n",
    "\n",
    "y_test = y_test.apply(lambda x: label(x))\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "689ba69b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 0,  ..., 0, 0, 0])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.tensor(y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "264576fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.,  ..., 0., 0., 0.], dtype=torch.float64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y.apply(lambda x: label(x))\n",
    "torch.tensor(y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93c963de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba744a6",
   "metadata": {},
   "source": [
    "`torch.nn.Embedding`:\n",
    "\n",
    "**torch.nn.Emebdding(num_embeddings, embedding_dim)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4388aea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-1.6270, -0.5891,  1.0201,  0.2022],\n",
       "          [-1.6835, -1.4850, -0.5055,  0.4733],\n",
       "          [ 1.8186,  0.6548, -0.1640,  0.4837]],\n",
       " \n",
       "         [[-1.6835, -1.4850, -0.5055,  0.4733],\n",
       "          [ 1.8186,  0.6548, -0.1640,  0.4837],\n",
       "          [-0.1582,  1.0103,  0.4638,  0.9874]]], grad_fn=<EmbeddingBackward0>),\n",
       " torch.Size([2, 3, 4]),\n",
       " torch.Size([2, 3, 4]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = nn.Embedding(5, 4) # total 5 words, each words have 4 dims\n",
    "'''\n",
    "the shape is (2, 3).\n",
    "        |||\n",
    "Word is like a batch, the batch size is 2, which means we have two data sample.\n",
    "Each data sample have 3 words, which equals to the padding length or num_steps.\n",
    "\n",
    "'''\n",
    "word = [[1, 2, 3], \n",
    "        [2, 3, 4]]\n",
    "\n",
    "embed = embedding(torch.LongTensor(word))\n",
    "embed, embed.size(), embed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4f2745",
   "metadata": {},
   "source": [
    "The output is `(2, 3, 4)`.\n",
    "Which is **(batch_size, padding_length, word_dims)**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52c3ec58",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_embedding_path = '../../glove.6B.100d/vec.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2139467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the -0.038194 -0.24487 0.72812 -0.39961 0.083172 0.043953 -0.39141 0.3344 -0.57545 0.087459 0.28787 -0.06731 0.30906 -0.26384 -0.13231 -0.20757 0.33395 -0.33848 -0.31743 -0.48336 0.1464 -0.37304 0.34577 0.052041 0.44946 -0.46971 0.02628 -0.54155 -0.15518 -0.14107 -0.039722 0.28277 0.14393 0.23464 -0.31021 0.086173 0.20397 0.52624 0.17164 -0.082378 -0.71787 -0.41531 0.20335 -0.12763 0.41367 0.55187 0.57908 -0.33477 -0.36559 -0.54857 -0.062892 0.26584 0.30205 0.99775 -0.80481 -3.0243 0.01254 -0.36942 2.2167 0.72201 -0.24978 0.92136 0.034514 0.46745 1.1079 -0.19358 -0.074575 0.23353 -0.052062 -0.22044 0.057162 -0.15806 -0.30798 -0.41625 0.37972 0.15006 -0.53212 -0.2055 -1.2526 0.071624 0.70565 0.49744 -0.42063 0.26148 -1.538 -0.30223 -0.073438 -0.28312 0.37104 -0.25217 0.016215 -0.017099 -0.38984 0.87424 -0.72569 -0.51058 -0.52028 -0.1459 0.8278 0.27062\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(glove_embedding_path, 'r') as f:\n",
    "    for line in f:\n",
    "        a = line\n",
    "        print(a)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f94518c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "403f5495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', '-0.038194', '-0.24487']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elems = a.rstrip().split(' ')\n",
    "elems[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "964c6966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [2, 3, 4]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor can be slicing\n",
    "\n",
    "l = [[1, 2, 3], \n",
    "     [2, 3, 4],\n",
    "     [3, 3, 1]]\n",
    "l = torch.tensor(l)\n",
    "\n",
    "l[torch.tensor([0, 1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ed2d654",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a3ed547b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenEmbedding:\n",
    "    def __init__(self, embedding_path):\n",
    "        '''\n",
    "        We need to create three things:\n",
    "        1. idx_to_token\n",
    "        2. idx_to_vec\n",
    "        3. token_to_idx\n",
    "        '''\n",
    "        self.idx_to_token, self.idx_to_vec = self._load_embedding(embedding_path)\n",
    "        self.unknown_idx = 0\n",
    "        self.token_to_idx = {token: idx for idx, token in enumerate(self.idx_to_token)}\n",
    "    \n",
    "    def _load_embedding(self, embedding_path):\n",
    "        idx_to_token, idx_to_vec = ['<unk>'], []\n",
    "        with open(embedding_path, 'r') as f:\n",
    "            for line in f:\n",
    "                elems = line.rstrip().split(' ')\n",
    "                token, elems = elems[0], [float(elem) for elem in elems[1:]]\n",
    "                # of course it will always be greater than one!!!\n",
    "                if len(elems) > 1:\n",
    "                    idx_to_token.append(token)\n",
    "                    idx_to_vec.append(elems)\n",
    "        '''\n",
    "        After that we need to add ['<unk>'] using all 0 vectors.\n",
    "        '''\n",
    "        idx_to_vec = [[0] * len(idx_to_vec[0])] + idx_to_vec\n",
    "        return idx_to_token, torch.tensor(idx_to_vec)\n",
    "    \n",
    "    def __getitem__(self, tokens):\n",
    "        indices = [self.token_to_idx.get(token, self.unknown_idx)\n",
    "                   for token in tokens]\n",
    "        vecs = self.idx_to_vec[torch.tensor(indices)]\n",
    "        return vecs\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.idx_to_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a68b8944",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_embedding = TokenEmbedding(glove_embedding_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55c75c3",
   "metadata": {},
   "source": [
    "What the `TokenEmbedding` class does is that:\n",
    "\n",
    "It takes token's idx in the `Vocab` class, \n",
    "and use `__getitem__` in itself, mapping them to vecs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ed5fa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eae1091f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLstm(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers):\n",
    "        super(BiLstm, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.encoder = nn.LSTM(embed_size, num_hiddens, num_layers=num_layers, bidirectional=True)\n",
    "        self.decoder = nn.Linear(num_hiddens * 2, 2) # 2 * 2 == 4\n",
    "\n",
    "    def forward(self, x):\n",
    "        embeddings = self.embedding(x.T)\n",
    "        # for faster storing\n",
    "        self.encoder.flatten_parameters()\n",
    "        out, _ = self.encoder(embeddings)\n",
    "        out = self.decoder(out[-1])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d131ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19365\n",
      "torch.Size([19365, 100])\n"
     ]
    }
   ],
   "source": [
    "from model import Config\n",
    "from data import TokenEmbedding, return_data, Vocab, build_iterator\n",
    "\n",
    "\n",
    "config = Config()\n",
    "X_train, X_test, y_train, y_test = return_data(config.data_path)\n",
    "vocab = Vocab(X_train, min_freq=config.min_freq, reserved_tokens=['<pad>'])\n",
    "print(len(vocab))\n",
    "pretrain_embedding = TokenEmbedding(config.embedding_path)\n",
    "embeds = pretrain_embedding[vocab.idx_to_token]\n",
    "print(embeds.shape)\n",
    "train_iter, test_iter = build_iterator(X_train, X_test, y_train, y_test, vocab, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ccb01b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = BiLstm(len(vocab), 100, 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b55381de",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.embedding.weight.data.copy_(embeds)\n",
    "net.embedding.weight.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa4e5901",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss(reduction=\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab43fd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a701ea1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rumours' 'non-rumours' nan]\n",
      "['rumours' 'non-rumours']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('Pheme.csv')\n",
    "print(df.Label.unique())\n",
    "df.dropna(axis=0, how='any', inplace=True)\n",
    "print(df.Label.unique())\n",
    "df.to_csv('Pheme.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e628c83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yhat shape torch.Size([64, 2])\n",
      "yshape torch.Size([64])\n",
      "loss tensor(0.6981, grad_fn=<NllLossBackward0>)\n",
      "-----\n",
      "yhat shape torch.Size([64, 2])\n",
      "yshape torch.Size([64])\n",
      "loss tensor(0.7035, grad_fn=<NllLossBackward0>)\n",
      "-----\n",
      "yhat shape torch.Size([64, 2])\n",
      "yshape torch.Size([64])\n",
      "loss tensor(0.7020, grad_fn=<NllLossBackward0>)\n",
      "-----\n",
      "yhat shape torch.Size([64, 2])\n",
      "yshape torch.Size([64])\n",
      "loss tensor(0.6989, grad_fn=<NllLossBackward0>)\n",
      "-----\n",
      "yhat shape torch.Size([64, 2])\n",
      "yshape torch.Size([64])\n",
      "loss tensor(0.6996, grad_fn=<NllLossBackward0>)\n",
      "-----\n",
      "yhat shape torch.Size([64, 2])\n",
      "yshape torch.Size([64])\n",
      "loss tensor(0.7012, grad_fn=<NllLossBackward0>)\n",
      "-----\n",
      "yhat shape torch.Size([64, 2])\n",
      "yshape torch.Size([64])\n",
      "loss tensor(0.7012, grad_fn=<NllLossBackward0>)\n",
      "-----\n",
      "yhat shape torch.Size([64, 2])\n",
      "yshape torch.Size([64])\n",
      "loss tensor(0.7004, grad_fn=<NllLossBackward0>)\n",
      "-----\n",
      "yhat shape torch.Size([64, 2])\n",
      "yshape torch.Size([64])\n",
      "loss tensor(0.6981, grad_fn=<NllLossBackward0>)\n",
      "-----\n",
      "yhat shape torch.Size([64, 2])\n",
      "yshape torch.Size([64])\n",
      "loss tensor(0.6989, grad_fn=<NllLossBackward0>)\n",
      "-----\n",
      "yhat shape torch.Size([64, 2])\n",
      "yshape torch.Size([64])\n",
      "loss tensor(0.6965, grad_fn=<NllLossBackward0>)\n",
      "-----\n",
      "yhat shape torch.Size([64, 2])\n",
      "yshape torch.Size([64])\n",
      "loss tensor(0.7027, grad_fn=<NllLossBackward0>)\n",
      "-----\n",
      "yhat shape torch.Size([64, 2])\n",
      "yshape torch.Size([64])\n",
      "loss tensor(0.6958, grad_fn=<NllLossBackward0>)\n",
      "-----\n",
      "yhat shape torch.Size([64, 2])\n",
      "yshape torch.Size([64])\n",
      "loss tensor(0.6981, grad_fn=<NllLossBackward0>)\n",
      "-----\n",
      "yhat shape torch.Size([64, 2])\n",
      "yshape torch.Size([64])\n",
      "loss tensor(0.6973, grad_fn=<NllLossBackward0>)\n",
      "-----\n",
      "yhat shape torch.Size([64, 2])\n",
      "yshape torch.Size([64])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Target -9223372036854775808 is out of bounds.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/l5/zwtc0m5n30qfv9j2sf49f0y80000gn/T/ipykernel_8167/262269929.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'yhat shape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_hat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'yshape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-----'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   2844\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2845\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2846\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: Target -9223372036854775808 is out of bounds."
     ]
    }
   ],
   "source": [
    "for X, y in train_iter:\n",
    "    y_hat = net(X)\n",
    "    print('yhat shape', y_hat.shape)\n",
    "    print('yshape', y.shape)\n",
    "    loss = f.cross_entropy(y_hat, y)\n",
    "    print('loss', loss)\n",
    "    print('-----')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d33442b",
   "metadata": {},
   "source": [
    "**torch.Size([35, 64, 200])**\n",
    "- padding_length = 35\n",
    "- batch_size = 64\n",
    "- 2 * hidden_state = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b7bf7290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c39f40e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 35])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75c28a0",
   "metadata": {},
   "source": [
    "64 rows, 35 columns\n",
    "\n",
    "going through the embedding layer it will become\n",
    "\n",
    "**[64, 35, 100]**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "31ead556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6774, 15027,    18,  ..., 13122,     5,  3301],\n",
       "        [    0,   579,   176,  ...,     9,  1123,   562],\n",
       "        [ 6820,    40,  6902,  ...,     0,  6902,     7],\n",
       "        ...,\n",
       "        [ 1086,    51,  2094,  ...,  1164,     0,    30],\n",
       "        [    0,  1239,  2416,  ...,     1,     1,     1],\n",
       "        [ 9002,  3298,     8,  ...,    23,   270,  1848]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d8944ed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([35, 64])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.T.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83061e49",
   "metadata": {},
   "source": [
    "`[35, 64, 100]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ddf4e443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2,  2],\n",
       "         [ 1,  2],\n",
       "         [ 4,  5]],\n",
       "\n",
       "        [[ 9, 10],\n",
       "         [ 6,  6],\n",
       "         [ 1, 10]],\n",
       "\n",
       "        [[ 2,  4],\n",
       "         [ 3,  3],\n",
       "         [ 8,  1]]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[[2, 2], [1, 2], [4, 5]],[[9, 10], [6, 6], [1, 10]],[[2, 4], [3, 3], [8, 1]]])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0245c090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3, 2])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "884513ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 2],\n",
       "        [1, 2],\n",
       "        [4, 5]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7cb5bf18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 4],\n",
       "        [3, 3],\n",
       "        [8, 1]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b551f318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 2, 2, 4],\n",
       "        [1, 2, 3, 3],\n",
       "        [4, 5, 8, 1]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((a[0], a[-1]), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4362e91c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([35, 64, 200])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0565916e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 200])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "5b29d7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('Pheme.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "a7be0322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>#BREAKING: A Germanwings Airbus A320 has crash...</td>\n",
       "      <td>rumours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Updated numbers @AP: BREAKING: #Germanwings CE...</td>\n",
       "      <td>rumours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>@YanniKouts @germanwings @flightradar24 A bit ...</td>\n",
       "      <td>rumours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>#Germanwings co-pilot suffered serious depress...</td>\n",
       "      <td>rumours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>@ThisIsGaZa إِنَّا لِلّهِ وَإِنَّـا إِلَيْهِ ر...</td>\n",
       "      <td>rumours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6419</th>\n",
       "      <td>6421</td>\n",
       "      <td>6420</td>\n",
       "      <td>Franz Marc: Horses... Update-#Gurlitt Nazi-Tai...</td>\n",
       "      <td>non-rumours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6420</th>\n",
       "      <td>6422</td>\n",
       "      <td>6421</td>\n",
       "      <td>Munich District Court has confirmed the applic...</td>\n",
       "      <td>non-rumours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6421</th>\n",
       "      <td>6423</td>\n",
       "      <td>6422</td>\n",
       "      <td>Where should the Gurlitt collection go?  :Many...</td>\n",
       "      <td>non-rumours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6422</th>\n",
       "      <td>6424</td>\n",
       "      <td>6423</td>\n",
       "      <td>@DrDonnaYates They should insure the Swiss art...</td>\n",
       "      <td>non-rumours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6423</th>\n",
       "      <td>6425</td>\n",
       "      <td>6424</td>\n",
       "      <td>‘The Gurlitt collection should be sold to bene...</td>\n",
       "      <td>non-rumours</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6424 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  Unnamed: 0.1  \\\n",
       "0              0             0   \n",
       "1              1             1   \n",
       "2              2             2   \n",
       "3              3             3   \n",
       "4              4             4   \n",
       "...          ...           ...   \n",
       "6419        6421          6420   \n",
       "6420        6422          6421   \n",
       "6421        6423          6422   \n",
       "6422        6424          6423   \n",
       "6423        6425          6424   \n",
       "\n",
       "                                                   Text        Label  \n",
       "0     #BREAKING: A Germanwings Airbus A320 has crash...      rumours  \n",
       "1     Updated numbers @AP: BREAKING: #Germanwings CE...      rumours  \n",
       "2     @YanniKouts @germanwings @flightradar24 A bit ...      rumours  \n",
       "3     #Germanwings co-pilot suffered serious depress...      rumours  \n",
       "4     @ThisIsGaZa إِنَّا لِلّهِ وَإِنَّـا إِلَيْهِ ر...      rumours  \n",
       "...                                                 ...          ...  \n",
       "6419  Franz Marc: Horses... Update-#Gurlitt Nazi-Tai...  non-rumours  \n",
       "6420  Munich District Court has confirmed the applic...  non-rumours  \n",
       "6421  Where should the Gurlitt collection go?  :Many...  non-rumours  \n",
       "6422  @DrDonnaYates They should insure the Swiss art...  non-rumours  \n",
       "6423  ‘The Gurlitt collection should be sold to bene...  non-rumours  \n",
       "\n",
       "[6424 rows x 4 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "56a008fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>#BREAKING: A Germanwings Airbus A320 has crash...</td>\n",
       "      <td>rumours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Updated numbers @AP: BREAKING: #Germanwings CE...</td>\n",
       "      <td>rumours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>@YanniKouts @germanwings @flightradar24 A bit ...</td>\n",
       "      <td>rumours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>#Germanwings co-pilot suffered serious depress...</td>\n",
       "      <td>rumours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>@ThisIsGaZa إِنَّا لِلّهِ وَإِنَّـا إِلَيْهِ ر...</td>\n",
       "      <td>rumours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>123</td>\n",
       "      <td>123</td>\n",
       "      <td>@delaynelee hubby thinks it was a malfunction ...</td>\n",
       "      <td>rumours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>@gatewaypundit I figured something putrid...wa...</td>\n",
       "      <td>rumours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>125</td>\n",
       "      <td>125</td>\n",
       "      <td>Is @magiorNYT even an employee of @nyt? \\nPlea...</td>\n",
       "      <td>rumours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>126</td>\n",
       "      <td>126</td>\n",
       "      <td>@LIVE_COVERAGE @MissWitch2310 @BBCBreaking I d...</td>\n",
       "      <td>rumours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>127</td>\n",
       "      <td>127</td>\n",
       "      <td>The #Germanwings #A320 plane that crashed in t...</td>\n",
       "      <td>rumours</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  Unnamed: 0.1  \\\n",
       "0             0             0   \n",
       "1             1             1   \n",
       "2             2             2   \n",
       "3             3             3   \n",
       "4             4             4   \n",
       "..          ...           ...   \n",
       "123         123           123   \n",
       "124         124           124   \n",
       "125         125           125   \n",
       "126         126           126   \n",
       "127         127           127   \n",
       "\n",
       "                                                  Text    Label  \n",
       "0    #BREAKING: A Germanwings Airbus A320 has crash...  rumours  \n",
       "1    Updated numbers @AP: BREAKING: #Germanwings CE...  rumours  \n",
       "2    @YanniKouts @germanwings @flightradar24 A bit ...  rumours  \n",
       "3    #Germanwings co-pilot suffered serious depress...  rumours  \n",
       "4    @ThisIsGaZa إِنَّا لِلّهِ وَإِنَّـا إِلَيْهِ ر...  rumours  \n",
       "..                                                 ...      ...  \n",
       "123  @delaynelee hubby thinks it was a malfunction ...  rumours  \n",
       "124  @gatewaypundit I figured something putrid...wa...  rumours  \n",
       "125  Is @magiorNYT even an employee of @nyt? \\nPlea...  rumours  \n",
       "126  @LIVE_COVERAGE @MissWitch2310 @BBCBreaking I d...  rumours  \n",
       "127  The #Germanwings #A320 plane that crashed in t...  rumours  \n",
       "\n",
       "[128 rows x 4 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo = df[:128]\n",
    "demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "5985c79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo.to_csv('demo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff788035",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
