{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ea73d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3d659b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    #BREAKING: A Germanwings Airbus A320 has crash...\n",
       " 1    Updated numbers @AP: BREAKING: #Germanwings CE...\n",
       " 2    @YanniKouts @germanwings @flightradar24 A bit ...\n",
       " 3    #Germanwings co-pilot suffered serious depress...\n",
       " 4    @ThisIsGaZa إِنَّا لِلّهِ وَإِنَّـا إِلَيْهِ ر...\n",
       " Name: Text, dtype: object,\n",
       " 0    rumours\n",
       " 1    rumours\n",
       " 2    rumours\n",
       " 3    rumours\n",
       " 4    rumours\n",
       " Name: Label, dtype: object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Pheme.csv')\n",
    "X = df['Text']\n",
    "y = df['Label']\n",
    "\n",
    "X.head(), y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e5f7070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7bf8f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dd0bda31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5140, 5140)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c9eb3b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1286, 1286)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "653627b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a1a34614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3408    0\n",
       "577     1\n",
       "3077    0\n",
       "6308    1\n",
       "2558    0\n",
       "       ..\n",
       "179     1\n",
       "3291    0\n",
       "2435    0\n",
       "5750    0\n",
       "6188    0\n",
       "Name: Label, Length: 1286, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def label(x):\n",
    "    if x == 'rumours':\n",
    "        x = 1\n",
    "    elif x == 'non-rumours':\n",
    "        x = 0\n",
    "    return x\n",
    "\n",
    "y_test = y_test.apply(lambda x: label(x))\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "689ba69b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 0,  ..., 0, 0, 0])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.tensor(y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "264576fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.,  ..., 0., 0., 0.], dtype=torch.float64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y.apply(lambda x: label(x))\n",
    "torch.tensor(y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93c963de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba744a6",
   "metadata": {},
   "source": [
    "`torch.nn.Embedding`:\n",
    "\n",
    "**torch.nn.Emebdding(num_embeddings, embedding_dim)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4388aea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-1.6270, -0.5891,  1.0201,  0.2022],\n",
       "          [-1.6835, -1.4850, -0.5055,  0.4733],\n",
       "          [ 1.8186,  0.6548, -0.1640,  0.4837]],\n",
       " \n",
       "         [[-1.6835, -1.4850, -0.5055,  0.4733],\n",
       "          [ 1.8186,  0.6548, -0.1640,  0.4837],\n",
       "          [-0.1582,  1.0103,  0.4638,  0.9874]]], grad_fn=<EmbeddingBackward0>),\n",
       " torch.Size([2, 3, 4]),\n",
       " torch.Size([2, 3, 4]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = nn.Embedding(5, 4) # total 5 words, each words have 4 dims\n",
    "'''\n",
    "the shape is (2, 3).\n",
    "        |||\n",
    "Word is like a batch, the batch size is 2, which means we have two data sample.\n",
    "Each data sample have 3 words, which equals to the padding length or num_steps.\n",
    "\n",
    "'''\n",
    "word = [[1, 2, 3], \n",
    "        [2, 3, 4]]\n",
    "\n",
    "embed = embedding(torch.LongTensor(word))\n",
    "embed, embed.size(), embed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4f2745",
   "metadata": {},
   "source": [
    "The output is `(2, 3, 4)`.\n",
    "Which is **(batch_size, padding_length, word_dims)**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52c3ec58",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_embedding_path = '../../glove.6B.100d/vec.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2139467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the -0.038194 -0.24487 0.72812 -0.39961 0.083172 0.043953 -0.39141 0.3344 -0.57545 0.087459 0.28787 -0.06731 0.30906 -0.26384 -0.13231 -0.20757 0.33395 -0.33848 -0.31743 -0.48336 0.1464 -0.37304 0.34577 0.052041 0.44946 -0.46971 0.02628 -0.54155 -0.15518 -0.14107 -0.039722 0.28277 0.14393 0.23464 -0.31021 0.086173 0.20397 0.52624 0.17164 -0.082378 -0.71787 -0.41531 0.20335 -0.12763 0.41367 0.55187 0.57908 -0.33477 -0.36559 -0.54857 -0.062892 0.26584 0.30205 0.99775 -0.80481 -3.0243 0.01254 -0.36942 2.2167 0.72201 -0.24978 0.92136 0.034514 0.46745 1.1079 -0.19358 -0.074575 0.23353 -0.052062 -0.22044 0.057162 -0.15806 -0.30798 -0.41625 0.37972 0.15006 -0.53212 -0.2055 -1.2526 0.071624 0.70565 0.49744 -0.42063 0.26148 -1.538 -0.30223 -0.073438 -0.28312 0.37104 -0.25217 0.016215 -0.017099 -0.38984 0.87424 -0.72569 -0.51058 -0.52028 -0.1459 0.8278 0.27062\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(glove_embedding_path, 'r') as f:\n",
    "    for line in f:\n",
    "        a = line\n",
    "        print(a)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f94518c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "403f5495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', '-0.038194', '-0.24487']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elems = a.rstrip().split(' ')\n",
    "elems[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "964c6966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [2, 3, 4]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor can be slicing\n",
    "\n",
    "l = [[1, 2, 3], \n",
    "     [2, 3, 4],\n",
    "     [3, 3, 1]]\n",
    "l = torch.tensor(l)\n",
    "\n",
    "l[torch.tensor([0, 1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a3ed547b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenEmbedding:\n",
    "    def __init__(self, embedding_path):\n",
    "        '''\n",
    "        We need to create three things:\n",
    "        1. idx_to_token\n",
    "        2. idx_to_vec\n",
    "        3. token_to_idx\n",
    "        '''\n",
    "        self.idx_to_token, self.idx_to_vec = self._load_embedding(embedding_path)\n",
    "        self.unknown_idx = 0\n",
    "        self.token_to_idx = {token: idx for idx, token in enumerate(self.idx_to_token)}\n",
    "    \n",
    "    def _load_embedding(self, embedding_path):\n",
    "        idx_to_token, idx_to_vec = ['<unk>'], []\n",
    "        with open(embedding_path, 'r') as f:\n",
    "            for line in f:\n",
    "                elems = line.rstrip().split(' ')\n",
    "                token, elems = elems[0], [float(elem) for elem in elems[1:]]\n",
    "                # of course it will always be greater than one!!!\n",
    "                if len(elems) > 1:\n",
    "                    idx_to_token.append(token)\n",
    "                    idx_to_vec.append(elems)\n",
    "        '''\n",
    "        After that we need to add ['<unk>'] using all 0 vectors.\n",
    "        '''\n",
    "        idx_to_vec = [[0] * len(idx_to_vec[0])] + idx_to_vec\n",
    "        return idx_to_token, torch.tensor(idx_to_vec)\n",
    "    \n",
    "    def __getitem__(self, tokens):\n",
    "        indices = [self.token_to_idx.get(token, self.unknown_idx)\n",
    "                   for token in tokens]\n",
    "        vecs = self.idx_to_vec[torch.tensor(indices)]\n",
    "        return vecs\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.idx_to_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a68b8944",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_embedding = TokenEmbedding(glove_embedding_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55c75c3",
   "metadata": {},
   "source": [
    "What the `TokenEmbedding` class does is that:\n",
    "\n",
    "It takes token's idx in the `Vocab` class, \n",
    "and use `__getitem__` in itself, mapping them to vecs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "eae1091f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLstm(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers):\n",
    "        super(BiLstm, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.encoder = nn.LSTM(embed_size, num_hiddens, num_layers=num_layers, bidirectional=True)\n",
    "        self.decoder = nn.Linear(num_hiddens * 2, 2) # 2 * 2 == 4\n",
    "\n",
    "    def forward(self, x):\n",
    "        embeddings = self.embedding(x.T)\n",
    "        # for faster storing\n",
    "        self.encoder.flatten_parameters()\n",
    "        out, _ = self.encoder(embeddings)\n",
    "        out = self.decoder(out[-1])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5d131ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19365\n",
      "torch.Size([19365, 100])\n"
     ]
    }
   ],
   "source": [
    "from model import Config\n",
    "from data import TokenEmbedding, return_data, Vocab, build_iterator\n",
    "\n",
    "\n",
    "config = Config()\n",
    "X_train, X_test, y_train, y_test = return_data(config.data_path)\n",
    "vocab = Vocab(X_train, min_freq=config.min_freq, reserved_tokens=['<pad>'])\n",
    "print(len(vocab))\n",
    "pretrain_embedding = TokenEmbedding(config.embedding_path)\n",
    "embeds = pretrain_embedding[vocab.idx_to_token]\n",
    "print(embeds.shape)\n",
    "train_iter, test_iter = build_iterator(X_train, X_test, y_train, y_test, vocab, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ccb01b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = BiLstm(len(vocab), 100, 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b55381de",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.embedding.weight.data.copy_(embeds)\n",
    "net.embedding.weight.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e628c83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 2])\n"
     ]
    }
   ],
   "source": [
    "for X, y in train_iter:\n",
    "    y_hat = net(X)\n",
    "#     print(y_hat)\n",
    "    print(y_hat.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d33442b",
   "metadata": {},
   "source": [
    "**torch.Size([35, 64, 200])**\n",
    "- padding_length = 35\n",
    "- batch_size = 64\n",
    "- 2 * hidden_state = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b7bf7290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476],\n",
       "        [-0.0332,  0.0476]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c39f40e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 35])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75c28a0",
   "metadata": {},
   "source": [
    "64 rows, 35 columns\n",
    "\n",
    "going through the embedding layer it will become\n",
    "\n",
    "**[64, 35, 100]**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "31ead556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6774, 15027,    18,  ..., 13122,     5,  3301],\n",
       "        [    0,   579,   176,  ...,     9,  1123,   562],\n",
       "        [ 6820,    40,  6902,  ...,     0,  6902,     7],\n",
       "        ...,\n",
       "        [ 1086,    51,  2094,  ...,  1164,     0,    30],\n",
       "        [    0,  1239,  2416,  ...,     1,     1,     1],\n",
       "        [ 9002,  3298,     8,  ...,    23,   270,  1848]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d8944ed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([35, 64])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.T.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83061e49",
   "metadata": {},
   "source": [
    "`[35, 64, 100]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ddf4e443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2,  2],\n",
       "         [ 1,  2],\n",
       "         [ 4,  5]],\n",
       "\n",
       "        [[ 9, 10],\n",
       "         [ 6,  6],\n",
       "         [ 1, 10]],\n",
       "\n",
       "        [[ 2,  4],\n",
       "         [ 3,  3],\n",
       "         [ 8,  1]]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[[2, 2], [1, 2], [4, 5]],[[9, 10], [6, 6], [1, 10]],[[2, 4], [3, 3], [8, 1]]])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0245c090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3, 2])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "884513ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 2],\n",
       "        [1, 2],\n",
       "        [4, 5]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7cb5bf18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 4],\n",
       "        [3, 3],\n",
       "        [8, 1]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b551f318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 2, 2, 4],\n",
       "        [1, 2, 3, 3],\n",
       "        [4, 5, 8, 1]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((a[0], a[-1]), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4362e91c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([35, 64, 200])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0565916e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 200])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a1957d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
